"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[903],{8234(e,n,i){i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>a});const t=JSON.parse('{"id":"build-retrieval-ready-doc-pipeline","title":"Build a Retrieval-Ready Documentation Pipeline on a Cloud VM","description":"Learn how to design and deploy a documentation pipeline optimized for both humans and AI retrieval systems using Docker, FastAPI, and a cloud VM.","source":"@site/docs/aiml/build-retrieval-ready-doc-pipeline.mdx","sourceDirName":".","slug":"/build-retrieval-ready-doc-pipeline","permalink":"/aiml/build-retrieval-ready-doc-pipeline","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Build a Retrieval-Ready Documentation Pipeline on a Cloud VM","description":"Learn how to design and deploy a documentation pipeline optimized for both humans and AI retrieval systems using Docker, FastAPI, and a cloud VM."},"sidebar":"aimlSidebar","previous":{"title":"Articles I wrote for DigitalOcean","permalink":"/aiml/do-articles"}}');var s=i(4848),r=i(8453);const l={title:"Build a Retrieval-Ready Documentation Pipeline on a Cloud VM",description:"Learn how to design and deploy a documentation pipeline optimized for both humans and AI retrieval systems using Docker, FastAPI, and a cloud VM."},o="Build a Retrieval-Ready Documentation Pipeline on a Cloud VM",c={},a=[{value:"How this tutorial connects to RAG systems",id:"how-this-tutorial-connects-to-rag-systems",level:3},{value:"What this tutorial covers",id:"what-this-tutorial-covers",level:2},{value:"Environment details",id:"environment-details",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Provisioning the cloud VM and installing Docker",id:"provisioning-the-cloud-vm-and-installing-docker",level:2},{value:"Create a cloud VM",id:"create-a-cloud-vm",level:3},{value:"Connect to the VM",id:"connect-to-the-vm",level:3},{value:"Install Docker Engine",id:"install-docker-engine",level:3},{value:"Update system packages",id:"update-system-packages",level:4},{value:"Add Docker\u2019s official GPG key",id:"add-dockers-official-gpg-key",level:4},{value:"Install Docker and Compose",id:"install-docker-and-compose",level:4},{value:"Deploy a FastAPI service with Docker Compose",id:"deploy-a-fastapi-service-with-docker-compose",level:2},{value:"Create the project directory",id:"create-the-project-directory",level:3},{value:"Create the FastAPI application",id:"create-the-fastapi-application",level:3},{value:"Create the Docker Compose configuration",id:"create-the-docker-compose-configuration",level:3},{value:"Authoring documentation for retrieval systems",id:"authoring-documentation-for-retrieval-systems",level:2},{value:"Create a documentation directory",id:"create-a-documentation-directory",level:3},{value:"Create the deployment documentation file",id:"create-the-deployment-documentation-file",level:3},{value:"Create the API source file",id:"create-the-api-source-file",level:3},{value:"Define the FastAPI application",id:"define-the-fastapi-application",level:4},{value:"Why this structure matters",id:"why-this-structure-matters",level:3},{value:"Converting structured Markdown into retrieval-ready chunks",id:"converting-structured-markdown-into-retrieval-ready-chunks",level:2},{value:"Create the chunking script",id:"create-the-chunking-script",level:3},{value:"Create a new file:",id:"create-a-new-file",level:4},{value:"Run the chunking script",id:"run-the-chunking-script",level:4},{value:"Why H3-based chunking improves retrieval",id:"why-h3-based-chunking-improves-retrieval",level:3},{value:"Future scope",id:"future-scope",level:3}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"build-a-retrieval-ready-documentation-pipeline-on-a-cloud-vm",children:"Build a Retrieval-Ready Documentation Pipeline on a Cloud VM"})}),"\n",(0,s.jsxs)(n.p,{children:["When you build a chatbot or a ",(0,s.jsx)("a",{href:"https://www.digitalocean.com/resources/articles/rag",target:"_blank",rel:"noopener noreferrer",children:"RAG"}),"-based assistant, the model does not magically know your product documentation, policies, or internal processes. So when a user asks:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"\u201cHow do I rotate my API key?\u201d"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"\u201cWhat\u2019s our refund policy for enterprise customers?\u201d"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"\u201cHow do I deploy this service on staging?\u201d"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The model doesn\u2019t already know your product docs. It only knows what it was trained on broadly; not your specific or up-to-date content. It must fetch the relevant information first based on semantic similarity (how closely two pieces of text match in meaning, not just keywords)."}),"\n",(0,s.jsx)(n.p,{children:"Here\u2019s what happens in simple terms:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The question is converted into an embedding."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The system searches a vector database."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"It retrieves the most relevant documentation chunks."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Those chunks are sent to the model as context."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The model generates an answer grounded in them."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"So the system isn\u2019t reading full pages. It\u2019s retrieving specific fragments of documentation."}),"\n",(0,s.jsx)(n.p,{children:"That\u2019s why structure matters. If your docs aren\u2019t cleanly chunked and well-labeled, retrieval becomes unreliable \u2014 and so do your answers."}),"\n",(0,s.jsx)(n.h3,{id:"how-this-tutorial-connects-to-rag-systems",children:"How this tutorial connects to RAG systems"}),"\n",(0,s.jsx)(n.p,{children:"Retrieval-Augmented Generation (RAG) systems rely on well-structured, semantically clean source content. While most RAG tutorials focus on embeddings, vector databases, and query pipelines, they assume the underlying documentation is already retrieval-ready."}),"\n",(0,s.jsx)(n.p,{children:"This tutorial addresses that foundational layer. Instead of building the retrieval engine itself, we design documentation in a way that makes it optimally consumable by retrieval systems. The structured chunks, stable section IDs, canonical URLs, and metadata we generate here are exactly what embedding pipelines and vector databases require downstream."}),"\n",(0,s.jsx)(n.p,{children:"In other words, this workflow prepares documentation to perform reliably inside a RAG architecture."}),"\n",(0,s.jsx)(n.p,{children:"In this tutorial, we will build a retrieval-ready documentation pipeline from scratch on a cloud VM. By the end, you will have:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A deployed FastAPI service running on Docker"}),"\n",(0,s.jsx)(n.li,{children:"Markdown documentation structured with semantic section boundaries"}),"\n",(0,s.jsx)(n.li,{children:"A custom chunking script that converts documentation into machine-readable JSON"}),"\n",(0,s.jsx)(n.li,{children:"Retrieval-ready metadata including section IDs, canonical URLs, and word counts"}),"\n",(0,s.jsxs)(n.li,{children:["A generated ",(0,s.jsx)(n.code,{children:"chunks.json"})," artifact suitable for embeddings or RAG systems"]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"what-this-tutorial-covers",children:"What this tutorial covers"}),"\n",(0,s.jsx)(n.p,{children:"We will:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Provision a cloud VM"}),"\n",(0,s.jsx)(n.li,{children:"Install Docker and Docker Compose"}),"\n",(0,s.jsx)(n.li,{children:"Deploy a simple API service"}),"\n",(0,s.jsx)(n.li,{children:"Author structured Markdown documentation"}),"\n",(0,s.jsx)(n.li,{children:"Build a Python chunking pipeline"}),"\n",(0,s.jsx)(n.li,{children:"Generate a retrieval-optimized JSON artifact"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"The goal is to design documentation that can be consumed by:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Humans"}),"\n",(0,s.jsx)(n.li,{children:"Search engines"}),"\n",(0,s.jsx)(n.li,{children:"Knowledge bases"}),"\n",(0,s.jsx)(n.li,{children:"RAG systems"}),"\n",(0,s.jsx)(n.li,{children:"AI agents"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"environment-details",children:"Environment details"}),"\n",(0,s.jsx)(n.p,{children:"This workflow was deployed in the following environment:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Cloud provider: DigitalOcean"}),"\n",(0,s.jsx)(n.li,{children:"VM size: 2 vCPUs, 4GB RAM"}),"\n",(0,s.jsx)(n.li,{children:"OS: Ubuntu 24.04 LTS (x64)"}),"\n",(0,s.jsx)(n.li,{children:"Container runtime: Docker Engine 29.x"}),"\n",(0,s.jsx)(n.li,{children:"Orchestration: Docker Compose v5.x"}),"\n",(0,s.jsx)(n.li,{children:"API framework: FastAPI"}),"\n",(0,s.jsx)(n.li,{children:"Reverse proxy: Nginx"}),"\n",(0,s.jsx)(n.li,{children:"Python version: 3.11 (slim image)"}),"\n",(0,s.jsx)(n.li,{children:"Documentation format: Markdown (H2/H3 structured)"}),"\n",(0,s.jsxs)(n.li,{children:["Output artifact: ",(0,s.jsx)(n.code,{children:"chunks.json"})]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsx)(n.p,{children:"Before starting, you should have:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A cloud account (DigitalOcean or equivalent)"}),"\n",(0,s.jsx)(n.li,{children:"Basic Linux command line familiarity"}),"\n",(0,s.jsxs)(n.li,{children:["Understanding of:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Docker fundamentals"}),"\n",(0,s.jsx)(n.li,{children:"Markdown structure"}),"\n",(0,s.jsx)(n.li,{children:"Basic Python scripting"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.li,{children:"Ability to SSH into a VM"}),"\n",(0,s.jsx)(n.li,{children:"Local browser access to the cloud console"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Optional but recommended:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Familiarity with RAG pipelines"}),"\n",(0,s.jsx)(n.li,{children:"Basic understanding of embeddings"}),"\n",(0,s.jsx)(n.li,{children:"Experience with FastAPI"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:"In the next section, we will provision the VM and configure Docker."}),"\n",(0,s.jsx)(n.h2,{id:"provisioning-the-cloud-vm-and-installing-docker",children:"Provisioning the cloud VM and installing Docker"}),"\n",(0,s.jsx)(n.p,{children:"To build a retrieval-ready documentation pipeline, we first need a stable runtime environment. Instead of running everything locally, we deploy on a cloud VM to simulate a real-world production setup."}),"\n",(0,s.jsx)(n.p,{children:"This ensures:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Isolation from local machine constraints"}),"\n",(0,s.jsx)(n.li,{children:"Reproducibility"}),"\n",(0,s.jsx)(n.li,{children:"Network-level testing"}),"\n",(0,s.jsx)(n.li,{children:"Infrastructure realism"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"create-a-cloud-vm",children:"Create a cloud VM"}),"\n",(0,s.jsx)(n.p,{children:"Log in to your cloud provider dashboard and create a new virtual machine with the following configuration:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"OS: Ubuntu 24.04 LTS (x64)"}),"\n",(0,s.jsx)(n.li,{children:"Size: 2 vCPUs, 4GB RAM"}),"\n",(0,s.jsx)(n.li,{children:"Disk: 120GB"}),"\n",(0,s.jsx)(n.li,{children:"Authentication: SSH key"}),"\n",(0,s.jsx)(n.li,{children:"Monitoring: Optional (enabled for observability)"}),"\n"]}),"\n",(0,s.jsxs)("figure",{style:{textAlign:"center",margin:"2rem 0"},children:[(0,s.jsx)("img",{src:"/img/aiml/doc-pipeline/create-droplet.png",alt:"DigitalOcean droplet creation page",style:{maxWidth:"100%"}}),(0,s.jsx)("figcaption",{style:{marginTop:"0.75rem",fontSize:"0.9rem",color:"#666"},children:(0,s.jsx)(n.p,{children:"DigitalOcean Droplet (VM) creation"})})]}),"\n",(0,s.jsx)(n.p,{children:"Once provisioned, note the public IPv4 address."}),"\n",(0,s.jsxs)("figure",{style:{textAlign:"center",margin:"2rem 0"},children:[(0,s.jsx)("img",{src:"/img/aiml/doc-pipeline/droplet-ip.png",alt:"DigitalOcean droplet IP address image",style:{maxWidth:"100%"}}),(0,s.jsx)("figcaption",{style:{marginTop:"0.75rem",fontSize:"0.9rem",color:"#666"},children:(0,s.jsx)(n.p,{children:"Created a DigitalOcean Droplet"})})]}),"\n",(0,s.jsx)(n.h3,{id:"connect-to-the-vm",children:"Connect to the VM"}),"\n",(0,s.jsx)(n.p,{children:"Use the web console or SSH:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"ssh root@your_public_ip\n"})}),"\n",(0,s.jsx)(n.h3,{id:"install-docker-engine",children:"Install Docker Engine"}),"\n",(0,s.jsx)(n.p,{children:"We install Docker directly from the official repository to ensure compatibility with the latest Compose plugin."}),"\n",(0,s.jsx)(n.h4,{id:"update-system-packages",children:"Update system packages"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"apt-get update\napt-get install -y ca-certificates curl gnupg\n"})}),"\n",(0,s.jsx)(n.h4,{id:"add-dockers-official-gpg-key",children:"Add Docker\u2019s official GPG key"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | \\\ngpg --dearmor -o /etc/apt/keyrings/docker.gpg\nchmod a+r /etc/apt/keyrings/docker.gpg\nAdd Docker repository\necho \\\n"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \\\nhttps://download.docker.com/linux/ubuntu \\\n$(. /etc/os-release && echo "$VERSION_CODENAME") stable" \\\n> /etc/apt/sources.list.d/docker.list\n'})}),"\n",(0,s.jsx)(n.h4,{id:"install-docker-and-compose",children:"Install Docker and Compose"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"apt-get update\napt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\nEnable and start Docker\nsystemctl enable docker\nsystemctl start docker\nVerify installation\ndocker --version\ndocker compose version\n"})}),"\n",(0,s.jsxs)("figure",{style:{textAlign:"center",margin:"2rem 0"},children:[(0,s.jsx)("img",{src:"/img/aiml/doc-pipeline/docker-installed.png",alt:"Terminal showing docker and docker compose versions",style:{maxWidth:"100%"}}),(0,s.jsx)("figcaption",{style:{marginTop:"0.75rem",fontSize:"0.9rem",color:"#666"},children:(0,s.jsx)(n.p,{children:"Verifying Docker Engine and Docker Compose installation."})})]}),"\n",(0,s.jsx)(n.p,{children:"If both commands return version numbers successfully, Docker is correctly installed."}),"\n",(0,s.jsx)(n.p,{children:"Why we use Docker instead of installing dependencies directly"}),"\n",(0,s.jsx)(n.p,{children:"Using Docker provides:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Deterministic environments"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Dependency isolation"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Reproducible builds"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Clean teardown and rebuild cycles"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Production parity"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This matters because retrieval pipelines often evolve. You want the ability to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Rebuild services"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Modify chunking logic"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Reprocess documentation"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Deploy changes quickly"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Containers make that workflow predictable."}),"\n",(0,s.jsx)(n.h2,{id:"deploy-a-fastapi-service-with-docker-compose",children:"Deploy a FastAPI service with Docker Compose"}),"\n",(0,s.jsx)(n.p,{children:"Now that Docker is installed, we will deploy a simple FastAPI application inside a container using Docker Compose. This service will later be the foundation for testing our documentation and retrieval pipeline."}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"create-the-project-directory",children:"Create the project directory"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/rag-docs-demo\ncd ~/rag-docs-demo\n"})}),"\n",(0,s.jsx)(n.p,{children:"This directory will contain:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The FastAPI application"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The Docker Compose configuration"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Supporting documentation files"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"The chunking script"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"create-the-fastapi-application",children:"Create the FastAPI application"}),"\n",(0,s.jsx)(n.p,{children:"Create a file named main.py:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'cat > main.py << \'PYEOF\'\nfrom fastapi import FastAPI\n\napp = FastAPI(title="Docs demo API")\n\n\n@app.get("/health")\ndef health():\n    return {"status": "ok"}\n\n@app.get("/hello")\ndef hello(name: str = "world"):\n    return {"message": f"hello, {name}"}\nPYEOF\n'})}),"\n",(0,s.jsx)(n.p,{children:"This application exposes two endpoints:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"/health"})," \u2014 used for service validation"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"/hello"})," \u2014 simple parameterized endpoint for testing"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"create-the-docker-compose-configuration",children:"Create the Docker Compose configuration"}),"\n",(0,s.jsxs)(n.p,{children:["Create a file named ",(0,s.jsx)(n.code,{children:"docker-compose.yml"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'cat > docker-compose.yml << \'YAMLEOF\'\nservices:\n  api:\n    image: python:3.11-slim\n    command: sh -c "pip install --no-cache-dir fastapi uvicorn && uvicorn main:app --host 0.0.0.0 --port 8000"\n    volumes:\n      - ./main.py:/main.py\n    ports:\n      - "8000:8000"\n    restart: unless-stopped\nYAMLEOF\n'})}),"\n",(0,s.jsx)(n.p,{children:"This configuration:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Uses a lightweight Python 3.11 image"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Installs FastAPI and Uvicorn at runtime"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Mounts the local main.py file"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Exposes port 8000"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Enables automatic restart"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Start the service"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker compose up -d\ndocker compose ps\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-mdx",children:'<figure style={{ textAlign: "center", margin: "2rem 0" }}>\n<img\n  src="/img/aiml/doc-pipeline/docker-compose-running.png"\n  alt="Docker compose ps output showing running FastAPI container"\n  style={{\n    maxWidth: "100%"\n  }}\n/>\n<figcaption style={{ marginTop: "0.75rem", fontSize: "0.9rem", color: "#666" }}>\n  FastAPI service running inside Docker.\n</figcaption>\n</figure>\n'})}),"\n",(0,s.jsx)(n.p,{children:"You should see the api container in a running state."}),"\n",(0,s.jsx)(n.p,{children:"Verify the API is reachable"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"curl http://localhost:8000/health\n"})}),"\n",(0,s.jsx)(n.p,{children:"Expected response:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{"status":"ok"}\n'})}),"\n",(0,s.jsxs)("figure",{style:{textAlign:"center",margin:"2rem 0"},children:[(0,s.jsx)("img",{src:"/img/aiml/doc-pipeline/health-endpoint.png",alt:"Terminal showing successful curl response from health endpoint",style:{maxWidth:"100%"}}),(0,s.jsx)("figcaption",{style:{marginTop:"0.75rem",fontSize:"0.9rem",color:"#666"},children:" Verifying the API health endpoint. "})]}),"\n",(0,s.jsx)(n.p,{children:'If you receive a JSON response with "status":"ok", the service is correctly deployed.'}),"\n",(0,s.jsx)(n.h2,{id:"authoring-documentation-for-retrieval-systems",children:"Authoring documentation for retrieval systems"}),"\n",(0,s.jsx)(n.p,{children:"At this point, the API is running. Instead of immediately building embeddings or a vector database, we focus on something more foundational:"}),"\n",(0,s.jsx)(n.p,{children:"Designing documentation that retrieval systems can understand."}),"\n",(0,s.jsx)(n.p,{children:"Most RAG implementations fail not because of the model \u2014 but because the source content is poorly structured."}),"\n",(0,s.jsx)(n.p,{children:"In this section, we will:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Create structured Markdown documentation"}),"\n",(0,s.jsx)(n.li,{children:"Use H2 for logical grouping"}),"\n",(0,s.jsx)(n.li,{children:"Use H3 as retrieval boundaries"}),"\n",(0,s.jsx)(n.li,{children:"Add stable section anchors"}),"\n",(0,s.jsx)(n.li,{children:"Prepare content for deterministic chunk extraction"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"create-a-documentation-directory",children:"Create a documentation directory"}),"\n",(0,s.jsx)(n.p,{children:"From the project root:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"mkdir docs\ncd docs\n"})}),"\n",(0,s.jsx)(n.p,{children:"This directory will contain all documentation files that will later be parsed into retrieval-ready chunks."}),"\n",(0,s.jsx)(n.h3,{id:"create-the-deployment-documentation-file",children:"Create the deployment documentation file"}),"\n",(0,s.jsxs)(n.p,{children:["Create a file named ",(0,s.jsx)(n.code,{children:"deploy.md"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"nano deploy.md\n"})}),"\n",(0,s.jsx)(n.p,{children:"Add the following structure:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# Deploy the API with Docker Compose\n\n## Create the project directory\n\n### Create the working directory on the Droplet\n"})}),"\n",(0,s.jsx)(n.p,{children:"This step creates the folder that contains the API source file and the Docker Compose configuration."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/rag-docs-demo\ncd ~/rag-docs-demo\nVerify the directory exists\n"})}),"\n",(0,s.jsx)(n.p,{children:"Expected behavior: the directory is created without errors."}),"\n",(0,s.jsx)(n.h3,{id:"create-the-api-source-file",children:"Create the API source file"}),"\n",(0,s.jsx)(n.h4,{id:"define-the-fastapi-application",children:"Define the FastAPI application"}),"\n",(0,s.jsxs)(n.p,{children:["This application exposes two endpoints: ",(0,s.jsx)(n.code,{children:"/health"})," and ",(0,s.jsx)(n.code,{children:"/hello"}),"."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'cat > main.py << \'PYEOF\'\nfrom fastapi import FastAPI\n\napp = FastAPI(title="Docs demo API")\n\n@app.get("/health")\ndef health():\n    return {"status": "ok"}\n\n@app.get("/hello")\ndef hello(name: str = "world"):\n    return {"message": f"hello, {name}"}\nPYEOF\n'})}),"\n",(0,s.jsx)(n.p,{children:"Start the service\nRun Docker Compose"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker compose up -d\ndocker compose ps\n"})}),"\n",(0,s.jsx)(n.p,{children:"Verify the API is reachable"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"curl http://localhost:8000/health\n"})}),"\n",(0,s.jsx)(n.p,{children:"Expected response:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'{"status":"ok"}\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"why-this-structure-matters",children:"Why this structure matters"}),"\n",(0,s.jsx)(n.p,{children:"We intentionally use:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"H2 for major task grouping"}),"\n",(0,s.jsx)(n.li,{children:"H3 for granular answer boundaries"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Each H3 section will become one retrieval chunk."}),"\n",(0,s.jsx)(n.p,{children:"This ensures:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Clean semantic boundaries"}),"\n",(0,s.jsx)(n.li,{children:"Better embedding precision"}),"\n",(0,s.jsx)(n.li,{children:"Reduced hallucination risk"}),"\n",(0,s.jsx)(n.li,{children:"Deterministic citation mapping"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsxs)("figure",{style:{textAlign:"center",margin:"2rem 0"},children:[(0,s.jsx)("img",{src:"/img/aiml/doc-pipeline/deploy-md-structure.png",alt:"Structured Markdown file with H2 and H3 boundaries",style:{maxWidth:"100%"}}),(0,s.jsx)("figcaption",{style:{marginTop:"0.75rem",fontSize:"0.9rem",color:"#666"},children:(0,s.jsx)(n.p,{children:"Structured Markdown with H2 grouping and H3 retrieval boundaries."})})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.p,{children:"In the next section, we will build a Python script that parses this Markdown and converts it into retrieval-ready JSON chunks."}),"\n",(0,s.jsx)(n.h2,{id:"converting-structured-markdown-into-retrieval-ready-chunks",children:"Converting structured Markdown into retrieval-ready chunks"}),"\n",(0,s.jsx)(n.p,{children:"Now that we have structured documentation, the next step is to transform it into machine-readable chunks."}),"\n",(0,s.jsx)(n.p,{children:"Retrieval systems do not consume Markdown directly. They require:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Clean content boundaries"}),"\n",(0,s.jsx)(n.li,{children:"Stable section identifiers"}),"\n",(0,s.jsx)(n.li,{children:"Canonical URLs"}),"\n",(0,s.jsx)(n.li,{children:"Metadata enrichment"}),"\n",(0,s.jsx)(n.li,{children:"Structured JSON output"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"In this section, we will build a lightweight Python script that:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Parses Markdown files"}),"\n",(0,s.jsx)(n.li,{children:"Splits content by H3 boundaries"}),"\n",(0,s.jsx)(n.li,{children:"Generates stable section IDs"}),"\n",(0,s.jsx)(n.li,{children:"Attaches canonical URLs"}),"\n",(0,s.jsx)(n.li,{children:"Exports structured JSON"}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"create-the-chunking-script",children:"Create the chunking script"}),"\n",(0,s.jsx)(n.p,{children:"Return to the project root:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cd ~/rag-docs-demo\n"})}),"\n",(0,s.jsx)(n.h4,{id:"create-a-new-file",children:"Create a new file:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"nano chunk_docs.py\n"})}),"\n",(0,s.jsx)(n.p,{children:"Paste the following code:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'import os\nimport re\nimport json\n\nDOCS_DIR = "docs"\n\ndef slugify(text):\n    return re.sub(r\'[^a-z0-9]+\', \'-\', text.lower()).strip(\'-\')\n\ndef parse_markdown(file_path):\n    with open(file_path, "r") as f:\n        lines = f.readlines()\n\n    # Remove H1 lines\n    lines = [line for line in lines if not line.startswith("# ")]\n\n    sections = []\n    current_section = None\n    buffer = []\n\n    for line in lines:\n        if line.startswith("### "):\n            if current_section:\n                sections.append({\n                    "section_title": current_section["title"],\n                    "section_id": current_section["id"],\n                    "content": "".join(buffer).strip()\n                })\n                buffer = []\n\n            title = line.strip().replace("### ", "").strip()\n            current_section = {\n                "title": title,\n                "id": slugify(title)\n            }\n\n        elif line.startswith("## "):\n            # H2 headings act as grouping only\n            continue\n        else:\n            buffer.append(line)\n\n    if current_section:\n        sections.append({\n            "section_title": current_section["title"],\n            "section_id": current_section["id"],\n            "content": "".join(buffer).strip()\n        })\n\n    return sections\n\ndef main():\n    all_chunks = []\n    base_url = "http://your-docs-domain.com"\n\n    for filename in os.listdir(DOCS_DIR):\n        if filename.endswith(".md"):\n            path = os.path.join(DOCS_DIR, filename)\n            sections = parse_markdown(path)\n\n            for section in sections:\n                content_text = section["content"]\n                word_count = len(content_text.split())\n\n                chunk = {\n                    "doc": filename,\n                    "section_title": section["section_title"],\n                    "section_id": section["section_id"],\n                    "url": f"{base_url}/{filename}#{section[\'section_id\']}",\n                    "word_count": word_count,\n                    "content": content_text\n                }\n\n                all_chunks.append(chunk)\n\n    with open("chunks.json", "w") as f:\n        json.dump(all_chunks, f, indent=2)\n\n    print("Chunk file generated: chunks.json")\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,s.jsx)(n.p,{children:"Save and exit."}),"\n",(0,s.jsx)(n.h4,{id:"run-the-chunking-script",children:"Run the chunking script"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python3 chunk_docs.py\n"})}),"\n",(0,s.jsx)(n.p,{children:"If successful, you should see:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"Chunk file generated: chunks.json\nInspect the generated artifact\nhead -n 40 chunks.json\n"})}),"\n",(0,s.jsx)(n.p,{children:"You should see structured JSON similar to:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'{\n  "doc": "deploy.md",\n  "section_title": "Create the working directory on the Droplet",\n  "section_id": "create-the-working-directory-on-the-droplet",\n  "url": "http://your-docs-domain.com/deploy.md#create-the-working-directory-on-the-droplet",\n  "word_count": 28,\n  "content": "..."\n}\n'})}),"\n",(0,s.jsxs)("figure",{style:{textAlign:"center",margin:"2rem 0"},children:[(0,s.jsx)("img",{src:"/img/aiml/doc-pipeline/chunks-generated.png",alt:"Terminal showing chunks.json file generated successfully",style:{maxWidth:"100%"}}),(0,s.jsx)("figcaption",{style:{marginTop:"0.75rem",fontSize:"0.9rem",color:"#666"},children:(0,s.jsx)(n.p,{children:"Retrieval-ready JSON artifact generated from structured Markdown."})})]}),"\n",(0,s.jsx)(n.h3,{id:"why-h3-based-chunking-improves-retrieval",children:"Why H3-based chunking improves retrieval"}),"\n",(0,s.jsx)(n.p,{children:"We intentionally chunk at the H3 level instead of H2."}),"\n",(0,s.jsx)(n.p,{children:"This provides:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Smaller semantic units"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"More precise embedding vectors"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Better retrieval recall"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Reduced hallucination risk"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Deterministic citation mapping"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"H2 headings remain logical grouping boundaries for humans, while H3 headings become retrieval boundaries for machines."}),"\n",(0,s.jsx)(n.p,{children:"At this point, your documentation is officially retrieval-ready."}),"\n",(0,s.jsx)(n.h3,{id:"future-scope",children:"Future scope"}),"\n",(0,s.jsx)(n.p,{children:"This tutorial stops at the retrieval-ready artifact stage. From here, you can extend the system in several directions:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Generate embeddings from ",(0,s.jsx)(n.code,{children:"chunks.json"})," using an embedding model"]}),"\n",(0,s.jsx)(n.li,{children:"Store vectors in a database such as pgvector or Elasticsearch"}),"\n",(0,s.jsx)(n.li,{children:"Build a semantic search endpoint on top of the stored vectors"}),"\n",(0,s.jsx)(n.li,{children:"Integrate an LLM to generate grounded responses"}),"\n",(0,s.jsx)(n.li,{children:"Add citation-aware response formatting using section IDs"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"These extensions transform this pipeline into a full RAG system."}),"\n",(0,s.jsx)(n.p,{children:"However, without structured and deterministic chunking, even the best models and databases will struggle."}),"\n",(0,s.jsx)(n.p,{children:"By designing documentation for retrieval first, you create a strong foundation for any AI-powered knowledge system."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453(e,n,i){i.d(n,{R:()=>l,x:()=>o});var t=i(6540);const s={},r=t.createContext(s);function l(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);